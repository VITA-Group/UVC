python -m torch.distributed.launch \
    --nproc_per_node=4 --master_port 6382 post_train.py \
    --pretrained 0 \
    --model_type "deit_small_patch16_224" \
    --model_path https://dl.fbaipublicfiles.com/deit/deit_small_patch16_224-cd65a155.pth \
    --checkpoint_dir /home/shixing/deit_small_patch16_224_16.pth.tar \
    --distillation-type soft \
    --distillation-alpha 0.1 \
    --train_batch_size 4 \
    --gpu_num '0,1,2,3' \
    --num_epochs 100 \
    --eval_every 1000 \
    --output_dir exp/ft_deit_small_patch16_224_nasprune_0.5 \
    --num_workers 64 \
    --learning_rate 1e-4